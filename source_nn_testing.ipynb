{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM71JpMGauoJlYTiDNgv8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WiamSkakri/KLab/blob/main/source_nn_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "eO3yyTYmGUB-"
      },
      "outputs": [],
      "source": [
        "  # from google.colab import files\n",
        "  # print(\"Click 'Choose Files' and select your CSV files...\")\n",
        "  # uploaded = files.upload()\n",
        "\n",
        "  # # After upload, check what was uploaded\n",
        "  # print(\"\\nUploaded files:\")\n",
        "  # for filename in uploaded.keys():\n",
        "  #     print(f\"- {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "Ud0q7ZpBHMfr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('VGG-16_direct_cpu_layers.csv')"
      ],
      "metadata": {
        "id": "7HAFcECtHwAi"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq2eyGxwKYiq",
        "outputId": "7f078b4e-2406-4d0e-c1b4-cbe30daf82f3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1300, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Columns: {df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k93tvkvWKr4T",
        "outputId": "b0575c78-d0c5-47c9-d7a1-c65ef0b70e2d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size', 'Input_Size',\n",
            "       'In_Channels', 'Out_Channels', 'Kernel_Size', 'Stride', 'Padding',\n",
            "       'Execution_Time_ms', 'Percentage_of_Total'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Columns ({len(df.columns)} total):\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNnEtuBRK4EN",
        "outputId": "8126295b-a873-48dd-bafc-e3a2ef528ded"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns (13 total):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvlL-hENLELQ",
        "outputId": "2b890d23-8ffb-4139-9d4a-04e5bcf79c49"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels', 'Kernel_Size', 'Stride', 'Padding', 'Execution_Time_ms', 'Percentage_of_Total']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8ela5TPLHau",
        "outputId": "295124d0-e092-4ed3-c8f0-eeeb7a07dc49"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows:\n",
            "    Model        Layer Algorithm Device  Batch_Size  Input_Size  In_Channels  \\\n",
            "0  VGG-16   features.0    direct    cpu           1         276            3   \n",
            "1  VGG-16   features.2    direct    cpu           1         276           64   \n",
            "2  VGG-16   features.5    direct    cpu           1         138           64   \n",
            "3  VGG-16   features.7    direct    cpu           1         138          128   \n",
            "4  VGG-16  features.10    direct    cpu           1          69          128   \n",
            "\n",
            "   Out_Channels  Kernel_Size  Stride  Padding  Execution_Time_ms  \\\n",
            "0            64            3       1        1          14.086580   \n",
            "1            64            3       1        1         240.864372   \n",
            "2           128            3       1        1         130.611897   \n",
            "3           128            3       1        1         271.925902   \n",
            "4           256            3       1        1         168.775129   \n",
            "\n",
            "   Percentage_of_Total  \n",
            "0             0.455488  \n",
            "1             7.788317  \n",
            "2             4.223318  \n",
            "3             8.792687  \n",
            "4             5.457321  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\Data types:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4XdSxo0LPE2",
        "outputId": "b85a57c9-d1ff-4080-9b6e-48b4c6983446"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Data types:\n",
            "Model                   object\n",
            "Layer                   object\n",
            "Algorithm               object\n",
            "Device                  object\n",
            "Batch_Size               int64\n",
            "Input_Size               int64\n",
            "In_Channels              int64\n",
            "Out_Channels             int64\n",
            "Kernel_Size              int64\n",
            "Stride                   int64\n",
            "Padding                  int64\n",
            "Execution_Time_ms      float64\n",
            "Percentage_of_Total    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dataframes = []\n",
        "\n",
        "\n",
        "# Filter for only YOUR neural network layer files (not sample data)\n",
        "all_files = os.listdir()\n",
        "csv_files = [f for f in all_files if f.endswith('_layers.csv')]\n",
        "\n",
        "print(\"Found YOUR CSV files:\")\n",
        "for i, file in enumerate(csv_files, 1):\n",
        "    print(f\"{i}. {file}\")\n",
        "\n",
        "print(f\"\\nTotal files to combine: {len(csv_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26uwjjPLLUrb",
        "outputId": "76cee644-17da-4eeb-ced1-d69dbbf41e77"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found YOUR CSV files:\n",
            "1. ResNet-152_direct_cpu_layers.csv\n",
            "2. DenseNet_direct_cpu_layers.csv\n",
            "3. VGG-16_smm_cpu_layers.csv\n",
            "4. VGG-16_direct_cpu_layers.csv\n",
            "5. GoogLeNet_smm_cpu_layers.csv\n",
            "6. GoogLeNet_direct_cpu_layers.csv\n",
            "7. ResNet-152_smm_cpu_layers.csv\n",
            "8. DenseNet_smm_cpu_layers.csv\n",
            "\n",
            "Total files to combine: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Combine only your neural network files\n",
        "all_dataframes = []\n",
        "\n",
        "for file in csv_files:\n",
        "    print(f\"Reading {file}...\")\n",
        "    df_temp = pd.read_csv(file)\n",
        "\n",
        "    # Add a column to track which file this data came from\n",
        "    df_temp['source_file'] = file\n",
        "\n",
        "    # Show info about each file\n",
        "    print(f\"  - Shape: {df_temp.shape}\")\n",
        "    print(f\"  - Model: {df_temp['Model'].iloc[0] if 'Model' in df_temp.columns else 'Unknown'}\")\n",
        "    print(f\"  - Algorithm: {df_temp['Algorithm'].iloc[0] if 'Algorithm' in df_temp.columns else 'Unknown'}\")\n",
        "\n",
        "    all_dataframes.append(df_temp)\n",
        "\n",
        "# Combine all dataframes\n",
        "df_combined = pd.concat(all_dataframes, ignore_index=True)\n",
        "\n",
        "print(f\"\\nâœ… SUCCESS! Combined dataset:\")\n",
        "print(f\"Shape: {df_combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgbU9tzDRNux",
        "outputId": "adcd979d-2180-40be-f7e3-7b3151ec7392"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading ResNet-152_direct_cpu_layers.csv...\n",
            "  - Shape: (15500, 14)\n",
            "  - Model: ResNet-152\n",
            "  - Algorithm: direct\n",
            "Reading DenseNet_direct_cpu_layers.csv...\n",
            "  - Shape: (16000, 14)\n",
            "  - Model: DenseNet\n",
            "  - Algorithm: direct\n",
            "Reading VGG-16_smm_cpu_layers.csv...\n",
            "  - Shape: (1300, 14)\n",
            "  - Model: VGG-16\n",
            "  - Algorithm: smm\n",
            "Reading VGG-16_direct_cpu_layers.csv...\n",
            "  - Shape: (1300, 14)\n",
            "  - Model: VGG-16\n",
            "  - Algorithm: direct\n",
            "Reading GoogLeNet_smm_cpu_layers.csv...\n",
            "  - Shape: (5700, 14)\n",
            "  - Model: GoogLeNet\n",
            "  - Algorithm: smm\n",
            "Reading GoogLeNet_direct_cpu_layers.csv...\n",
            "  - Shape: (5700, 14)\n",
            "  - Model: GoogLeNet\n",
            "  - Algorithm: direct\n",
            "Reading ResNet-152_smm_cpu_layers.csv...\n",
            "  - Shape: (15500, 14)\n",
            "  - Model: ResNet-152\n",
            "  - Algorithm: smm\n",
            "Reading DenseNet_smm_cpu_layers.csv...\n",
            "  - Shape: (16000, 14)\n",
            "  - Model: DenseNet\n",
            "  - Algorithm: smm\n",
            "\n",
            "âœ… SUCCESS! Combined dataset:\n",
            "Shape: (77000, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data distribution by Model and Algorithm:\")\n",
        "distribution = df_combined.groupby(['Model', 'Algorithm']).size().reset_index(name='Count')\n",
        "print(distribution)\n",
        "\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df_combined.columns.tolist())\n",
        "\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_combined.head())\n",
        "\n",
        "# Save the combined file\n",
        "df_combined.to_csv('combined_cnn_data.csv', index=False)\n",
        "print(f\"\\nðŸ’¾ Saved combined data as 'combined_cnn_data.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV5mMAYrR2xo",
        "outputId": "c292ee8a-c7e5-4117-92cd-0b619929fb7e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data distribution by Model and Algorithm:\n",
            "        Model Algorithm  Count\n",
            "0    DenseNet    direct  16000\n",
            "1    DenseNet       smm  16000\n",
            "2   GoogLeNet    direct   5700\n",
            "3   GoogLeNet       smm   5700\n",
            "4  ResNet-152    direct  15500\n",
            "5  ResNet-152       smm  15500\n",
            "6      VGG-16    direct   1300\n",
            "7      VGG-16       smm   1300\n",
            "\n",
            "Column names:\n",
            "['Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels', 'Kernel_Size', 'Stride', 'Padding', 'Execution_Time_ms', 'Percentage_of_Total', 'source_file']\n",
            "\n",
            "First few rows:\n",
            "        Model                  Layer Algorithm Device  Batch_Size  Input_Size  \\\n",
            "0  ResNet-152                  conv1    direct    cpu           1         345   \n",
            "1  ResNet-152         layer1.0.conv1    direct    cpu           1          87   \n",
            "2  ResNet-152         layer1.0.conv2    direct    cpu           1          87   \n",
            "3  ResNet-152         layer1.0.conv3    direct    cpu           1          87   \n",
            "4  ResNet-152  layer1.0.downsample.0    direct    cpu           1          87   \n",
            "\n",
            "   In_Channels  Out_Channels  Kernel_Size  Stride  Padding  Execution_Time_ms  \\\n",
            "0            3            64            7       2        3          74.356270   \n",
            "1           64            64            1       1        0          18.627143   \n",
            "2           64            64            3       1        1          81.663489   \n",
            "3           64           256            1       1        0          60.292411   \n",
            "4           64           256            1       1        0          56.851649   \n",
            "\n",
            "   Percentage_of_Total                       source_file  \n",
            "0             0.503425  ResNet-152_direct_cpu_layers.csv  \n",
            "1             0.126114  ResNet-152_direct_cpu_layers.csv  \n",
            "2             0.552898  ResNet-152_direct_cpu_layers.csv  \n",
            "3             0.408207  ResNet-152_direct_cpu_layers.csv  \n",
            "4             0.384911  ResNet-152_direct_cpu_layers.csv  \n",
            "\n",
            "ðŸ’¾ Saved combined data as 'combined_cnn_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = df_combined.drop('Percentage_of_Total', axis=1)\n"
      ],
      "metadata": {
        "id": "pr1J888hSH0E"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRemaining columns:\")\n",
        "print(df_combined.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McXbuNVqTrnY",
        "outputId": "26c1ebee-ad15-4cd3-8894-f6829f4bcfcd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Remaining columns:\n",
            "['Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels', 'Kernel_Size', 'Stride', 'Padding', 'Execution_Time_ms', 'source_file']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = df_combined.drop('source_file', axis=1)\n",
        "print(\"\\nRemaining columns:\")\n",
        "print(df_combined.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh7ur_sOTuQE",
        "outputId": "38f393e2-f1ac-4034-e74a-47b3c8a8d2e1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Remaining columns:\n",
            "['Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels', 'Kernel_Size', 'Stride', 'Padding', 'Execution_Time_ms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "K_ulWrnaT1zB"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare your ML dataset (if you haven't already)\n",
        "target = 'Execution_Time_ms'\n",
        "input_features = [\n",
        "    'Model', 'Layer', 'Algorithm', 'Device', 'Batch_Size',\n",
        "    'Input_Size', 'In_Channels', 'Out_Channels',\n",
        "    'Kernel_Size', 'Stride', 'Padding'\n",
        "]\n",
        "\n",
        "df_ml = df_combined[input_features + [target]].copy()\n",
        "print(f\"Dataset ready: {df_ml.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV0LtkFeXwS7",
        "outputId": "e09f0853-5e0f-4056-88e8-eb0cfd531841"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready: (77000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df_ml):\n",
        "    \"\"\"Prepare data for PyTorch neural network\"\"\"\n",
        "\n",
        "    # Separate categorical and numerical features\n",
        "    categorical_features = ['Model', 'Layer', 'Algorithm', 'Device']\n",
        "    numerical_features = ['Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels',\n",
        "                          'Kernel_Size', 'Stride', 'Padding']\n",
        "\n",
        "    # Handle categorical variables with Label Encoding\n",
        "    label_encoders = {}\n",
        "    df_encoded = df_ml.copy()\n",
        "\n",
        "    for feature in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[feature + '_encoded'] = le.fit_transform(df_encoded[feature])\n",
        "        label_encoders[feature] = le\n",
        "        print(f\"{feature} encoding:\")\n",
        "        for i, label in enumerate(le.classes_):\n",
        "            print(f\"  {label} -> {i}\")\n",
        "        print()\n",
        "\n",
        "    # Select encoded features for model\n",
        "    feature_columns = [f + '_encoded' for f in categorical_features] + numerical_features\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df_encoded[feature_columns].values\n",
        "    y = df_encoded['Execution_Time_ms'].values\n",
        "\n",
        "    # Scale features (important for neural networks)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
        "    print(f\"Target vector shape: {y.shape}\")\n",
        "\n",
        "    return X_scaled, y, scaler, label_encoders, feature_columns"
      ],
      "metadata": {
        "id": "M1EBgM2KVupN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExecutionTimePredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ExecutionTimePredictor, self).__init__()\n",
        "\n",
        "        # Define the neural network layers\n",
        "        self.network = nn.Sequential(\n",
        "            # Input layer -> Hidden layer 1\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Hidden layer 1 -> Hidden layer 2\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Hidden layer 2 -> Hidden layer 3\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            # Hidden layer 3 -> Output layer\n",
        "            nn.Linear(32, 1)  # Single output for regression\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "iF-sHsllWWld"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Neural Network for CNN Execution Time Prediction\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ========== STEP 1: DATA PREPARATION ==========\n",
        "\n",
        "def prepare_data(df_ml):\n",
        "    \"\"\"Prepare data for PyTorch neural network\"\"\"\n",
        "\n",
        "    # Separate categorical and numerical features\n",
        "    categorical_features = ['Model', 'Layer', 'Algorithm', 'Device']\n",
        "    numerical_features = ['Batch_Size', 'Input_Size', 'In_Channels', 'Out_Channels',\n",
        "                          'Kernel_Size', 'Stride', 'Padding']\n",
        "\n",
        "    # Handle categorical variables with Label Encoding\n",
        "    label_encoders = {}\n",
        "    df_encoded = df_ml.copy()\n",
        "\n",
        "    for feature in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[feature + '_encoded'] = le.fit_transform(df_encoded[feature])\n",
        "        label_encoders[feature] = le\n",
        "        print(f\"{feature} encoding:\")\n",
        "        for i, label in enumerate(le.classes_):\n",
        "            print(f\"  {label} -> {i}\")\n",
        "        print()\n",
        "\n",
        "    # Select encoded features for model\n",
        "    feature_columns = [f + '_encoded' for f in categorical_features] + numerical_features\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df_encoded[feature_columns].values\n",
        "    y = df_encoded['Execution_Time_ms'].values\n",
        "\n",
        "    # Scale features (important for neural networks)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
        "    print(f\"Target vector shape: {y.shape}\")\n",
        "\n",
        "    return X_scaled, y, scaler, label_encoders, feature_columns\n",
        "\n",
        "# ========== STEP 2: NEURAL NETWORK ARCHITECTURE ==========\n",
        "\n",
        "class ExecutionTimePredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ExecutionTimePredictor, self).__init__()\n",
        "\n",
        "        # Define the neural network layers\n",
        "        self.network = nn.Sequential(\n",
        "            # Input layer -> Hidden layer 1\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Hidden layer 1 -> Hidden layer 2\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Hidden layer 2 -> Hidden layer 3\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            # Hidden layer 3 -> Output layer\n",
        "            nn.Linear(32, 1)  # Single output for regression\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# ========== STEP 3: TRAINING FUNCTION ==========\n",
        "\n",
        "def train_model(X_train, y_train, X_val, y_val, input_size, epochs=100):\n",
        "    \"\"\"Train the neural network\"\"\"\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(X_train)\n",
        "    y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
        "    X_val_tensor = torch.FloatTensor(X_val)\n",
        "    y_val_tensor = torch.FloatTensor(y_val).view(-1, 1)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Initialize model, loss function, and optimizer\n",
        "    model = ExecutionTimePredictor(input_size)\n",
        "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_train_loss = 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val_tensor)\n",
        "            val_loss = criterion(val_outputs, y_val_tensor)\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    return model, train_losses, val_losses"
      ],
      "metadata": {
        "id": "8sREJSbMWhlD"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"Evaluate the trained model\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        X_test_tensor = torch.FloatTensor(X_test)\n",
        "        y_pred_tensor = model(X_test_tensor)\n",
        "        y_pred = y_pred_tensor.numpy().flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Model Performance:\")\n",
        "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
        "    print(f\"RÂ² Score: {r2:.4f}\")\n",
        "\n",
        "    return y_pred, {'mse': mse, 'rmse': rmse, 'r2': r2}"
      ],
      "metadata": {
        "id": "S8oLCRIjWz0g"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(train_losses, val_losses, y_test, y_pred):\n",
        "    \"\"\"Plot training progress and predictions\"\"\"\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot training/validation loss\n",
        "    ax1.plot(train_losses, label='Training Loss')\n",
        "    ax1.plot(val_losses, label='Validation Loss')\n",
        "    ax1.set_title('Model Training Progress')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot actual vs predicted\n",
        "    ax2.scatter(y_test, y_pred, alpha=0.6)\n",
        "    ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    ax2.set_title('Actual vs Predicted Execution Time')\n",
        "    ax2.set_xlabel('Actual Execution Time (ms)')\n",
        "    ax2.set_ylabel('Predicted Execution Time (ms)')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cxf1ybFIW5i9"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pytorch_training(df_ml):\n",
        "    \"\"\"Complete workflow for training PyTorch model\"\"\"\n",
        "\n",
        "    print(\"ðŸš€ Starting PyTorch Neural Network Training for Execution Time Prediction\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Step 1: Prepare data\n",
        "    print(\"Step 1: Preparing data...\")\n",
        "    X, y, scaler, label_encoders, feature_columns = prepare_data(df_ml)\n",
        "\n",
        "    # Step 2: Split data\n",
        "    print(\"Step 2: Splitting data...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Further split training data for validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {X_train.shape}\")\n",
        "    print(f\"Validation set: {X_val.shape}\")\n",
        "    print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "    # Step 3: Train model\n",
        "    print(\"\\nStep 3: Training neural network...\")\n",
        "    model, train_losses, val_losses = train_model(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        input_size=X.shape[1],\n",
        "        epochs=100\n",
        "    )\n",
        "\n",
        "    # Step 4: Evaluate model\n",
        "    print(\"\\nStep 4: Evaluating model...\")\n",
        "    y_pred, metrics = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # Step 5: Visualize results\n",
        "    print(\"\\nStep 5: Plotting results...\")\n",
        "    plot_results(train_losses, val_losses, y_test, y_pred)\n",
        "\n",
        "    return model, scaler, label_encoders, metrics"
      ],
      "metadata": {
        "id": "nwYCa-UCW9wz"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_execution_time(model, scaler, label_encoders,\n",
        "                             model_name, layer, algorithm, device,\n",
        "                             batch_size, input_size, in_channels, out_channels,\n",
        "                             kernel_size, stride, padding):\n",
        "    \"\"\"Predict execution time for new configuration\"\"\"\n",
        "\n",
        "    # Encode categorical variables\n",
        "    model_encoded = label_encoders['Model'].transform([model_name])[0]\n",
        "    layer_encoded = label_encoders['Layer'].transform([layer])[0]\n",
        "    algorithm_encoded = label_encoders['Algorithm'].transform([algorithm])[0]\n",
        "    device_encoded = label_encoders['Device'].transform([device])[0]\n",
        "\n",
        "    # Create feature vector\n",
        "    features = np.array([[\n",
        "        model_encoded, layer_encoded, algorithm_encoded, device_encoded,\n",
        "        batch_size, input_size, in_channels, out_channels,\n",
        "        kernel_size, stride, padding\n",
        "    ]])\n",
        "\n",
        "    # Scale features\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # Make prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(torch.FloatTensor(features_scaled))\n",
        "        predicted_time = prediction.item()\n",
        "\n",
        "    print(f\"Predicted execution time: {predicted_time:.2f} ms\")\n",
        "    return predicted_time\n"
      ],
      "metadata": {
        "id": "IHVD2CETXTJk"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, scaler, label_encoders, metrics = run_pytorch_training(df_ml)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_VWTdrXpoo",
        "outputId": "7c68cc76-86ed-4152-87be-38753baabc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting PyTorch Neural Network Training for Execution Time Prediction\n",
            "======================================================================\n",
            "Step 1: Preparing data...\n",
            "Model encoding:\n",
            "  DenseNet -> 0\n",
            "  GoogLeNet -> 1\n",
            "  ResNet-152 -> 2\n",
            "  VGG-16 -> 3\n",
            "\n",
            "Layer encoding:\n",
            "  conv1 -> 0\n",
            "  conv1.conv -> 1\n",
            "  conv2.conv -> 2\n",
            "  conv3.conv -> 3\n",
            "  features.0 -> 4\n",
            "  features.10 -> 5\n",
            "  features.12 -> 6\n",
            "  features.14 -> 7\n",
            "  features.17 -> 8\n",
            "  features.19 -> 9\n",
            "  features.2 -> 10\n",
            "  features.21 -> 11\n",
            "  features.24 -> 12\n",
            "  features.26 -> 13\n",
            "  features.28 -> 14\n",
            "  features.5 -> 15\n",
            "  features.7 -> 16\n",
            "  features.conv0 -> 17\n",
            "  features.denseblock1.denselayer1.conv1 -> 18\n",
            "  features.denseblock1.denselayer1.conv2 -> 19\n",
            "  features.denseblock1.denselayer2.conv1 -> 20\n",
            "  features.denseblock1.denselayer2.conv2 -> 21\n",
            "  features.denseblock1.denselayer3.conv1 -> 22\n",
            "  features.denseblock1.denselayer3.conv2 -> 23\n",
            "  features.denseblock1.denselayer4.conv1 -> 24\n",
            "  features.denseblock1.denselayer4.conv2 -> 25\n",
            "  features.denseblock1.denselayer5.conv1 -> 26\n",
            "  features.denseblock1.denselayer5.conv2 -> 27\n",
            "  features.denseblock1.denselayer6.conv1 -> 28\n",
            "  features.denseblock1.denselayer6.conv2 -> 29\n",
            "  features.denseblock2.denselayer1.conv1 -> 30\n",
            "  features.denseblock2.denselayer1.conv2 -> 31\n",
            "  features.denseblock2.denselayer10.conv1 -> 32\n",
            "  features.denseblock2.denselayer10.conv2 -> 33\n",
            "  features.denseblock2.denselayer11.conv1 -> 34\n",
            "  features.denseblock2.denselayer11.conv2 -> 35\n",
            "  features.denseblock2.denselayer12.conv1 -> 36\n",
            "  features.denseblock2.denselayer12.conv2 -> 37\n",
            "  features.denseblock2.denselayer2.conv1 -> 38\n",
            "  features.denseblock2.denselayer2.conv2 -> 39\n",
            "  features.denseblock2.denselayer3.conv1 -> 40\n",
            "  features.denseblock2.denselayer3.conv2 -> 41\n",
            "  features.denseblock2.denselayer4.conv1 -> 42\n",
            "  features.denseblock2.denselayer4.conv2 -> 43\n",
            "  features.denseblock2.denselayer5.conv1 -> 44\n",
            "  features.denseblock2.denselayer5.conv2 -> 45\n",
            "  features.denseblock2.denselayer6.conv1 -> 46\n",
            "  features.denseblock2.denselayer6.conv2 -> 47\n",
            "  features.denseblock2.denselayer7.conv1 -> 48\n",
            "  features.denseblock2.denselayer7.conv2 -> 49\n",
            "  features.denseblock2.denselayer8.conv1 -> 50\n",
            "  features.denseblock2.denselayer8.conv2 -> 51\n",
            "  features.denseblock2.denselayer9.conv1 -> 52\n",
            "  features.denseblock2.denselayer9.conv2 -> 53\n",
            "  features.denseblock3.denselayer1.conv1 -> 54\n",
            "  features.denseblock3.denselayer1.conv2 -> 55\n",
            "  features.denseblock3.denselayer10.conv1 -> 56\n",
            "  features.denseblock3.denselayer10.conv2 -> 57\n",
            "  features.denseblock3.denselayer11.conv1 -> 58\n",
            "  features.denseblock3.denselayer11.conv2 -> 59\n",
            "  features.denseblock3.denselayer12.conv1 -> 60\n",
            "  features.denseblock3.denselayer12.conv2 -> 61\n",
            "  features.denseblock3.denselayer13.conv1 -> 62\n",
            "  features.denseblock3.denselayer13.conv2 -> 63\n",
            "  features.denseblock3.denselayer14.conv1 -> 64\n",
            "  features.denseblock3.denselayer14.conv2 -> 65\n",
            "  features.denseblock3.denselayer15.conv1 -> 66\n",
            "  features.denseblock3.denselayer15.conv2 -> 67\n",
            "  features.denseblock3.denselayer16.conv1 -> 68\n",
            "  features.denseblock3.denselayer16.conv2 -> 69\n",
            "  features.denseblock3.denselayer17.conv1 -> 70\n",
            "  features.denseblock3.denselayer17.conv2 -> 71\n",
            "  features.denseblock3.denselayer18.conv1 -> 72\n",
            "  features.denseblock3.denselayer18.conv2 -> 73\n",
            "  features.denseblock3.denselayer19.conv1 -> 74\n",
            "  features.denseblock3.denselayer19.conv2 -> 75\n",
            "  features.denseblock3.denselayer2.conv1 -> 76\n",
            "  features.denseblock3.denselayer2.conv2 -> 77\n",
            "  features.denseblock3.denselayer20.conv1 -> 78\n",
            "  features.denseblock3.denselayer20.conv2 -> 79\n",
            "  features.denseblock3.denselayer21.conv1 -> 80\n",
            "  features.denseblock3.denselayer21.conv2 -> 81\n",
            "  features.denseblock3.denselayer22.conv1 -> 82\n",
            "  features.denseblock3.denselayer22.conv2 -> 83\n",
            "  features.denseblock3.denselayer23.conv1 -> 84\n",
            "  features.denseblock3.denselayer23.conv2 -> 85\n",
            "  features.denseblock3.denselayer24.conv1 -> 86\n",
            "  features.denseblock3.denselayer24.conv2 -> 87\n",
            "  features.denseblock3.denselayer25.conv1 -> 88\n",
            "  features.denseblock3.denselayer25.conv2 -> 89\n",
            "  features.denseblock3.denselayer26.conv1 -> 90\n",
            "  features.denseblock3.denselayer26.conv2 -> 91\n",
            "  features.denseblock3.denselayer27.conv1 -> 92\n",
            "  features.denseblock3.denselayer27.conv2 -> 93\n",
            "  features.denseblock3.denselayer28.conv1 -> 94\n",
            "  features.denseblock3.denselayer28.conv2 -> 95\n",
            "  features.denseblock3.denselayer29.conv1 -> 96\n",
            "  features.denseblock3.denselayer29.conv2 -> 97\n",
            "  features.denseblock3.denselayer3.conv1 -> 98\n",
            "  features.denseblock3.denselayer3.conv2 -> 99\n",
            "  features.denseblock3.denselayer30.conv1 -> 100\n",
            "  features.denseblock3.denselayer30.conv2 -> 101\n",
            "  features.denseblock3.denselayer31.conv1 -> 102\n",
            "  features.denseblock3.denselayer31.conv2 -> 103\n",
            "  features.denseblock3.denselayer32.conv1 -> 104\n",
            "  features.denseblock3.denselayer32.conv2 -> 105\n",
            "  features.denseblock3.denselayer33.conv1 -> 106\n",
            "  features.denseblock3.denselayer33.conv2 -> 107\n",
            "  features.denseblock3.denselayer34.conv1 -> 108\n",
            "  features.denseblock3.denselayer34.conv2 -> 109\n",
            "  features.denseblock3.denselayer35.conv1 -> 110\n",
            "  features.denseblock3.denselayer35.conv2 -> 111\n",
            "  features.denseblock3.denselayer36.conv1 -> 112\n",
            "  features.denseblock3.denselayer36.conv2 -> 113\n",
            "  features.denseblock3.denselayer4.conv1 -> 114\n",
            "  features.denseblock3.denselayer4.conv2 -> 115\n",
            "  features.denseblock3.denselayer5.conv1 -> 116\n",
            "  features.denseblock3.denselayer5.conv2 -> 117\n",
            "  features.denseblock3.denselayer6.conv1 -> 118\n",
            "  features.denseblock3.denselayer6.conv2 -> 119\n",
            "  features.denseblock3.denselayer7.conv1 -> 120\n",
            "  features.denseblock3.denselayer7.conv2 -> 121\n",
            "  features.denseblock3.denselayer8.conv1 -> 122\n",
            "  features.denseblock3.denselayer8.conv2 -> 123\n",
            "  features.denseblock3.denselayer9.conv1 -> 124\n",
            "  features.denseblock3.denselayer9.conv2 -> 125\n",
            "  features.denseblock4.denselayer1.conv1 -> 126\n",
            "  features.denseblock4.denselayer1.conv2 -> 127\n",
            "  features.denseblock4.denselayer10.conv1 -> 128\n",
            "  features.denseblock4.denselayer10.conv2 -> 129\n",
            "  features.denseblock4.denselayer11.conv1 -> 130\n",
            "  features.denseblock4.denselayer11.conv2 -> 131\n",
            "  features.denseblock4.denselayer12.conv1 -> 132\n",
            "  features.denseblock4.denselayer12.conv2 -> 133\n",
            "  features.denseblock4.denselayer13.conv1 -> 134\n",
            "  features.denseblock4.denselayer13.conv2 -> 135\n",
            "  features.denseblock4.denselayer14.conv1 -> 136\n",
            "  features.denseblock4.denselayer14.conv2 -> 137\n",
            "  features.denseblock4.denselayer15.conv1 -> 138\n",
            "  features.denseblock4.denselayer15.conv2 -> 139\n",
            "  features.denseblock4.denselayer16.conv1 -> 140\n",
            "  features.denseblock4.denselayer16.conv2 -> 141\n",
            "  features.denseblock4.denselayer17.conv1 -> 142\n",
            "  features.denseblock4.denselayer17.conv2 -> 143\n",
            "  features.denseblock4.denselayer18.conv1 -> 144\n",
            "  features.denseblock4.denselayer18.conv2 -> 145\n",
            "  features.denseblock4.denselayer19.conv1 -> 146\n",
            "  features.denseblock4.denselayer19.conv2 -> 147\n",
            "  features.denseblock4.denselayer2.conv1 -> 148\n",
            "  features.denseblock4.denselayer2.conv2 -> 149\n",
            "  features.denseblock4.denselayer20.conv1 -> 150\n",
            "  features.denseblock4.denselayer20.conv2 -> 151\n",
            "  features.denseblock4.denselayer21.conv1 -> 152\n",
            "  features.denseblock4.denselayer21.conv2 -> 153\n",
            "  features.denseblock4.denselayer22.conv1 -> 154\n",
            "  features.denseblock4.denselayer22.conv2 -> 155\n",
            "  features.denseblock4.denselayer23.conv1 -> 156\n",
            "  features.denseblock4.denselayer23.conv2 -> 157\n",
            "  features.denseblock4.denselayer24.conv1 -> 158\n",
            "  features.denseblock4.denselayer24.conv2 -> 159\n",
            "  features.denseblock4.denselayer3.conv1 -> 160\n",
            "  features.denseblock4.denselayer3.conv2 -> 161\n",
            "  features.denseblock4.denselayer4.conv1 -> 162\n",
            "  features.denseblock4.denselayer4.conv2 -> 163\n",
            "  features.denseblock4.denselayer5.conv1 -> 164\n",
            "  features.denseblock4.denselayer5.conv2 -> 165\n",
            "  features.denseblock4.denselayer6.conv1 -> 166\n",
            "  features.denseblock4.denselayer6.conv2 -> 167\n",
            "  features.denseblock4.denselayer7.conv1 -> 168\n",
            "  features.denseblock4.denselayer7.conv2 -> 169\n",
            "  features.denseblock4.denselayer8.conv1 -> 170\n",
            "  features.denseblock4.denselayer8.conv2 -> 171\n",
            "  features.denseblock4.denselayer9.conv1 -> 172\n",
            "  features.denseblock4.denselayer9.conv2 -> 173\n",
            "  features.transition1.conv -> 174\n",
            "  features.transition2.conv -> 175\n",
            "  features.transition3.conv -> 176\n",
            "  inception3a.branch1.conv -> 177\n",
            "  inception3a.branch2.0.conv -> 178\n",
            "  inception3a.branch2.1.conv -> 179\n",
            "  inception3a.branch3.0.conv -> 180\n",
            "  inception3a.branch3.1.conv -> 181\n",
            "  inception3a.branch4.1.conv -> 182\n",
            "  inception3b.branch1.conv -> 183\n",
            "  inception3b.branch2.0.conv -> 184\n",
            "  inception3b.branch2.1.conv -> 185\n",
            "  inception3b.branch3.0.conv -> 186\n",
            "  inception3b.branch3.1.conv -> 187\n",
            "  inception3b.branch4.1.conv -> 188\n",
            "  inception4a.branch1.conv -> 189\n",
            "  inception4a.branch2.0.conv -> 190\n",
            "  inception4a.branch2.1.conv -> 191\n",
            "  inception4a.branch3.0.conv -> 192\n",
            "  inception4a.branch3.1.conv -> 193\n",
            "  inception4a.branch4.1.conv -> 194\n",
            "  inception4b.branch1.conv -> 195\n",
            "  inception4b.branch2.0.conv -> 196\n",
            "  inception4b.branch2.1.conv -> 197\n",
            "  inception4b.branch3.0.conv -> 198\n",
            "  inception4b.branch3.1.conv -> 199\n",
            "  inception4b.branch4.1.conv -> 200\n",
            "  inception4c.branch1.conv -> 201\n",
            "  inception4c.branch2.0.conv -> 202\n",
            "  inception4c.branch2.1.conv -> 203\n",
            "  inception4c.branch3.0.conv -> 204\n",
            "  inception4c.branch3.1.conv -> 205\n",
            "  inception4c.branch4.1.conv -> 206\n",
            "  inception4d.branch1.conv -> 207\n",
            "  inception4d.branch2.0.conv -> 208\n",
            "  inception4d.branch2.1.conv -> 209\n",
            "  inception4d.branch3.0.conv -> 210\n",
            "  inception4d.branch3.1.conv -> 211\n",
            "  inception4d.branch4.1.conv -> 212\n",
            "  inception4e.branch1.conv -> 213\n",
            "  inception4e.branch2.0.conv -> 214\n",
            "  inception4e.branch2.1.conv -> 215\n",
            "  inception4e.branch3.0.conv -> 216\n",
            "  inception4e.branch3.1.conv -> 217\n",
            "  inception4e.branch4.1.conv -> 218\n",
            "  inception5a.branch1.conv -> 219\n",
            "  inception5a.branch2.0.conv -> 220\n",
            "  inception5a.branch2.1.conv -> 221\n",
            "  inception5a.branch3.0.conv -> 222\n",
            "  inception5a.branch3.1.conv -> 223\n",
            "  inception5a.branch4.1.conv -> 224\n",
            "  inception5b.branch1.conv -> 225\n",
            "  inception5b.branch2.0.conv -> 226\n",
            "  inception5b.branch2.1.conv -> 227\n",
            "  inception5b.branch3.0.conv -> 228\n",
            "  inception5b.branch3.1.conv -> 229\n",
            "  inception5b.branch4.1.conv -> 230\n",
            "  layer1.0.conv1 -> 231\n",
            "  layer1.0.conv2 -> 232\n",
            "  layer1.0.conv3 -> 233\n",
            "  layer1.0.downsample.0 -> 234\n",
            "  layer1.1.conv1 -> 235\n",
            "  layer1.1.conv2 -> 236\n",
            "  layer1.1.conv3 -> 237\n",
            "  layer1.2.conv1 -> 238\n",
            "  layer1.2.conv2 -> 239\n",
            "  layer1.2.conv3 -> 240\n",
            "  layer2.0.conv1 -> 241\n",
            "  layer2.0.conv2 -> 242\n",
            "  layer2.0.conv3 -> 243\n",
            "  layer2.0.downsample.0 -> 244\n",
            "  layer2.1.conv1 -> 245\n",
            "  layer2.1.conv2 -> 246\n",
            "  layer2.1.conv3 -> 247\n",
            "  layer2.2.conv1 -> 248\n",
            "  layer2.2.conv2 -> 249\n",
            "  layer2.2.conv3 -> 250\n",
            "  layer2.3.conv1 -> 251\n",
            "  layer2.3.conv2 -> 252\n",
            "  layer2.3.conv3 -> 253\n",
            "  layer2.4.conv1 -> 254\n",
            "  layer2.4.conv2 -> 255\n",
            "  layer2.4.conv3 -> 256\n",
            "  layer2.5.conv1 -> 257\n",
            "  layer2.5.conv2 -> 258\n",
            "  layer2.5.conv3 -> 259\n",
            "  layer2.6.conv1 -> 260\n",
            "  layer2.6.conv2 -> 261\n",
            "  layer2.6.conv3 -> 262\n",
            "  layer2.7.conv1 -> 263\n",
            "  layer2.7.conv2 -> 264\n",
            "  layer2.7.conv3 -> 265\n",
            "  layer3.0.conv1 -> 266\n",
            "  layer3.0.conv2 -> 267\n",
            "  layer3.0.conv3 -> 268\n",
            "  layer3.0.downsample.0 -> 269\n",
            "  layer3.1.conv1 -> 270\n",
            "  layer3.1.conv2 -> 271\n",
            "  layer3.1.conv3 -> 272\n",
            "  layer3.10.conv1 -> 273\n",
            "  layer3.10.conv2 -> 274\n",
            "  layer3.10.conv3 -> 275\n",
            "  layer3.11.conv1 -> 276\n",
            "  layer3.11.conv2 -> 277\n",
            "  layer3.11.conv3 -> 278\n",
            "  layer3.12.conv1 -> 279\n",
            "  layer3.12.conv2 -> 280\n",
            "  layer3.12.conv3 -> 281\n",
            "  layer3.13.conv1 -> 282\n",
            "  layer3.13.conv2 -> 283\n",
            "  layer3.13.conv3 -> 284\n",
            "  layer3.14.conv1 -> 285\n",
            "  layer3.14.conv2 -> 286\n",
            "  layer3.14.conv3 -> 287\n",
            "  layer3.15.conv1 -> 288\n",
            "  layer3.15.conv2 -> 289\n",
            "  layer3.15.conv3 -> 290\n",
            "  layer3.16.conv1 -> 291\n",
            "  layer3.16.conv2 -> 292\n",
            "  layer3.16.conv3 -> 293\n",
            "  layer3.17.conv1 -> 294\n",
            "  layer3.17.conv2 -> 295\n",
            "  layer3.17.conv3 -> 296\n",
            "  layer3.18.conv1 -> 297\n",
            "  layer3.18.conv2 -> 298\n",
            "  layer3.18.conv3 -> 299\n",
            "  layer3.19.conv1 -> 300\n",
            "  layer3.19.conv2 -> 301\n",
            "  layer3.19.conv3 -> 302\n",
            "  layer3.2.conv1 -> 303\n",
            "  layer3.2.conv2 -> 304\n",
            "  layer3.2.conv3 -> 305\n",
            "  layer3.20.conv1 -> 306\n",
            "  layer3.20.conv2 -> 307\n",
            "  layer3.20.conv3 -> 308\n",
            "  layer3.21.conv1 -> 309\n",
            "  layer3.21.conv2 -> 310\n",
            "  layer3.21.conv3 -> 311\n",
            "  layer3.22.conv1 -> 312\n",
            "  layer3.22.conv2 -> 313\n",
            "  layer3.22.conv3 -> 314\n",
            "  layer3.23.conv1 -> 315\n",
            "  layer3.23.conv2 -> 316\n",
            "  layer3.23.conv3 -> 317\n",
            "  layer3.24.conv1 -> 318\n",
            "  layer3.24.conv2 -> 319\n",
            "  layer3.24.conv3 -> 320\n",
            "  layer3.25.conv1 -> 321\n",
            "  layer3.25.conv2 -> 322\n",
            "  layer3.25.conv3 -> 323\n",
            "  layer3.26.conv1 -> 324\n",
            "  layer3.26.conv2 -> 325\n",
            "  layer3.26.conv3 -> 326\n",
            "  layer3.27.conv1 -> 327\n",
            "  layer3.27.conv2 -> 328\n",
            "  layer3.27.conv3 -> 329\n",
            "  layer3.28.conv1 -> 330\n",
            "  layer3.28.conv2 -> 331\n",
            "  layer3.28.conv3 -> 332\n",
            "  layer3.29.conv1 -> 333\n",
            "  layer3.29.conv2 -> 334\n",
            "  layer3.29.conv3 -> 335\n",
            "  layer3.3.conv1 -> 336\n",
            "  layer3.3.conv2 -> 337\n",
            "  layer3.3.conv3 -> 338\n",
            "  layer3.30.conv1 -> 339\n",
            "  layer3.30.conv2 -> 340\n",
            "  layer3.30.conv3 -> 341\n",
            "  layer3.31.conv1 -> 342\n",
            "  layer3.31.conv2 -> 343\n",
            "  layer3.31.conv3 -> 344\n",
            "  layer3.32.conv1 -> 345\n",
            "  layer3.32.conv2 -> 346\n",
            "  layer3.32.conv3 -> 347\n",
            "  layer3.33.conv1 -> 348\n",
            "  layer3.33.conv2 -> 349\n",
            "  layer3.33.conv3 -> 350\n",
            "  layer3.34.conv1 -> 351\n",
            "  layer3.34.conv2 -> 352\n",
            "  layer3.34.conv3 -> 353\n",
            "  layer3.35.conv1 -> 354\n",
            "  layer3.35.conv2 -> 355\n",
            "  layer3.35.conv3 -> 356\n",
            "  layer3.4.conv1 -> 357\n",
            "  layer3.4.conv2 -> 358\n",
            "  layer3.4.conv3 -> 359\n",
            "  layer3.5.conv1 -> 360\n",
            "  layer3.5.conv2 -> 361\n",
            "  layer3.5.conv3 -> 362\n",
            "  layer3.6.conv1 -> 363\n",
            "  layer3.6.conv2 -> 364\n",
            "  layer3.6.conv3 -> 365\n",
            "  layer3.7.conv1 -> 366\n",
            "  layer3.7.conv2 -> 367\n",
            "  layer3.7.conv3 -> 368\n",
            "  layer3.8.conv1 -> 369\n",
            "  layer3.8.conv2 -> 370\n",
            "  layer3.8.conv3 -> 371\n",
            "  layer3.9.conv1 -> 372\n",
            "  layer3.9.conv2 -> 373\n",
            "  layer3.9.conv3 -> 374\n",
            "  layer4.0.conv1 -> 375\n",
            "  layer4.0.conv2 -> 376\n",
            "  layer4.0.conv3 -> 377\n",
            "  layer4.0.downsample.0 -> 378\n",
            "  layer4.1.conv1 -> 379\n",
            "  layer4.1.conv2 -> 380\n",
            "  layer4.1.conv3 -> 381\n",
            "  layer4.2.conv1 -> 382\n",
            "  layer4.2.conv2 -> 383\n",
            "  layer4.2.conv3 -> 384\n",
            "\n",
            "Algorithm encoding:\n",
            "  direct -> 0\n",
            "  smm -> 1\n",
            "\n",
            "Device encoding:\n",
            "  cpu -> 0\n",
            "\n",
            "Feature matrix shape: (77000, 11)\n",
            "Target vector shape: (77000,)\n",
            "Step 2: Splitting data...\n",
            "Training set: (49280, 11)\n",
            "Validation set: (12320, 11)\n",
            "Test set: (15400, 11)\n",
            "\n",
            "Step 3: Training neural network...\n",
            "Epoch [20/100], Train Loss: 3223.4957, Val Loss: 2198.0176\n",
            "Epoch [40/100], Train Loss: 2197.3136, Val Loss: 2805.4199\n",
            "Epoch [60/100], Train Loss: 1704.2201, Val Loss: 1002.9561\n",
            "Epoch [80/100], Train Loss: 1542.5967, Val Loss: 619.4243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w6_TTkVJXS9m"
      }
    }
  ]
}