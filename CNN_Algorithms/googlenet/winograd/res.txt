Error: winograd not implemented for stride not equal to 1

(ai3_env) [wxs428@gput068 winograd]$ ls
job.sh  python.py
(ai3_env) [wxs428@gput068 winograd]$ vim python.py 
(ai3_env) [wxs428@gput068 winograd]$ python python.py 
================================================================================
GOOGLENET WINOGRAD IMPLEMENTATION WITH AI3 LIBRARY
================================================================================
CUDA Device Information:
  ✓ CUDA is available
  ✓ CUDA version: 12.4
  ✓ Number of GPUs: 1
  ✓ Current GPU: NVIDIA L40S
  ✓ GPU Memory: 44.4 GB
  ✓ CUDA context initialized successfully

Configuration:
  Model: GoogleNet
  Algorithm: winograd
  Device: cuda
  Batch size: 1
  Iterations per input size: 10
  Input sizes to test: 1

Loading GoogleNet model...
✓ GoogleNet model loaded successfully

Original model loaded. Analyzing structure...
Found 57 Conv2D layers in original model

Applying AI3 winograd algorithm conversion...
✓ AI3 conversion completed successfully

============================================================
MODEL STRUCTURE ANALYSIS
============================================================
✓ AI3 Layer: conv1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 3, 7, 7])
✓ AI3 Layer: conv2.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 64, 1, 1])
✓ AI3 Layer: conv3.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([192, 64, 3, 3])
✓ AI3 Layer: inception3a.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 192, 1, 1])
✓ AI3 Layer: inception3a.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([96, 192, 1, 1])
✓ AI3 Layer: inception3a.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 96, 3, 3])
✓ AI3 Layer: inception3a.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([16, 192, 1, 1])
✓ AI3 Layer: inception3a.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 16, 3, 3])
✓ AI3 Layer: inception3a.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 192, 1, 1])
✓ AI3 Layer: inception3b.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 256, 1, 1])
✓ AI3 Layer: inception3b.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 256, 1, 1])
✓ AI3 Layer: inception3b.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([192, 128, 3, 3])
✓ AI3 Layer: inception3b.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 256, 1, 1])
✓ AI3 Layer: inception3b.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([96, 32, 3, 3])
✓ AI3 Layer: inception3b.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 256, 1, 1])
✓ AI3 Layer: inception4a.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([192, 480, 1, 1])
✓ AI3 Layer: inception4a.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([96, 480, 1, 1])
✓ AI3 Layer: inception4a.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([208, 96, 3, 3])
✓ AI3 Layer: inception4a.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([16, 480, 1, 1])
✓ AI3 Layer: inception4a.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([48, 16, 3, 3])
✓ AI3 Layer: inception4a.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 480, 1, 1])
✓ AI3 Layer: inception4b.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([160, 512, 1, 1])
✓ AI3 Layer: inception4b.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([112, 512, 1, 1])
✓ AI3 Layer: inception4b.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([224, 112, 3, 3])
✓ AI3 Layer: inception4b.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([24, 512, 1, 1])
✓ AI3 Layer: inception4b.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 24, 3, 3])
✓ AI3 Layer: inception4b.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 512, 1, 1])
✓ AI3 Layer: inception4c.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 512, 1, 1])
✓ AI3 Layer: inception4c.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 512, 1, 1])
✓ AI3 Layer: inception4c.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([256, 128, 3, 3])
✓ AI3 Layer: inception4c.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([24, 512, 1, 1])
✓ AI3 Layer: inception4c.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 24, 3, 3])
✓ AI3 Layer: inception4c.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 512, 1, 1])
✓ AI3 Layer: inception4d.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([112, 512, 1, 1])
✓ AI3 Layer: inception4d.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([144, 512, 1, 1])
✓ AI3 Layer: inception4d.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([288, 144, 3, 3])
✓ AI3 Layer: inception4d.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 512, 1, 1])
✓ AI3 Layer: inception4d.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 32, 3, 3])
✓ AI3 Layer: inception4d.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([64, 512, 1, 1])
✓ AI3 Layer: inception4e.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([256, 528, 1, 1])
✓ AI3 Layer: inception4e.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([160, 528, 1, 1])
✓ AI3 Layer: inception4e.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([320, 160, 3, 3])
✓ AI3 Layer: inception4e.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 528, 1, 1])
✓ AI3 Layer: inception4e.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 32, 3, 3])
✓ AI3 Layer: inception4e.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 528, 1, 1])
✓ AI3 Layer: inception5a.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([256, 832, 1, 1])
✓ AI3 Layer: inception5a.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([160, 832, 1, 1])
✓ AI3 Layer: inception5a.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([320, 160, 3, 3])
✓ AI3 Layer: inception5a.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([32, 832, 1, 1])
✓ AI3 Layer: inception5a.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 32, 3, 3])
✓ AI3 Layer: inception5a.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 832, 1, 1])
✓ AI3 Layer: inception5b.branch1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([384, 832, 1, 1])
✓ AI3 Layer: inception5b.branch2.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([192, 832, 1, 1])
✓ AI3 Layer: inception5b.branch2.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([384, 192, 3, 3])
✓ AI3 Layer: inception5b.branch3.0.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([48, 832, 1, 1])
✓ AI3 Layer: inception5b.branch3.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 48, 3, 3])
✓ AI3 Layer: inception5b.branch4.1.conv
  - Algorithm: winograd
  - Weight shape: torch.Size([128, 832, 1, 1])

============================================================
CONVERSION SUMMARY:
  Total Conv2D layers: 57
  AI3 converted: 57
  PyTorch remaining: 0
  Conversion rate: 100.0%
============================================================


Analyzing device placement after AI3 conversion...
✓ AI3 device distribution:
  - Parameters on CUDA: 0/173
  - Parameters on CPU: 173/173
  - Mixed device usage is expected with AI3
  - AI3 layers on CUDA: 0
  - AI3 layers on CPU: 57

Starting performance testing...
This will test the model with various input sizes to measure Winograd performance.

[1/1] Testing with input size 379x379
  ✓ Created input tensor: torch.Size([1, 3, 379, 379]) on cpu
  GPU Memory - Allocated: 0.00 GB, Reserved: 0.00 GB
  Running warmup...
  ✗ Error during warmup: winograd not implemented for stride not equal to 1 see `Supported Algorithms for cudnnConvolutionForward() 2D Convolutions. Filter descriptor wDesc: _NCHW` at https://docs.nvidia.com/deeplearning/cudnn/latest/api/cudnn-cnn-library.html
  Note: This may be expected with ai3 mixed CPU/GPU usage
  GPU Memory at error: 0.00 GB allocated
  Measuring performance over 10 iterations...
    Iteration 1/10
  ✗ Error during performance measurement: winograd not implemented for stride not equal to 1 see `Supported Algorithms for cudnnConvolutionForward() 2D Convolutions. Filter descriptor wDesc: _NCHW` at https://docs.nvidia.com/deeplearning/cudnn/latest/api/cudnn-cnn-library.html

================================================================================
GOOGLENET WINOGRAD TESTING COMPLETED
================================================================================
Results saved to:
  - Overall performance: /home/wxs428/googlenet/winograd/GoogleNet_winograd_cuda_overall.csv
  - Layer-wise performance: /home/wxs428/googlenet/winograd/GoogleNet_winograd_cuda_layers.csv

Summary:
  ✓ Tested 1 different input sizes
  ✓ 10 iterations per input size
  ✓ Winograd algorithm optimization using AI3 library
  ✓ Comprehensive layer-wise performance analysis

Next steps:
  1. Analyze the CSV files to compare Winograd performance vs standard convolution
  2. Run the same test with different algorithms (direct, smm, etc.) for comparison
  3. Test on GPU (set device='cuda') for hardware-accelerated Winograd operations
================================================================================
(ai3_env) [wxs428@gput068 winograd]$ 