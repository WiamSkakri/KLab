Unsupported algorithm

(ai3_env) [wxs428@gput034 some]$ ls
(ai3_env) [wxs428@gput034 some]$ ls
(ai3_env) [wxs428@gput034 some]$ vim python.py
(ai3_env) [wxs428@gput034 some]$ python python.py 
================================================================================
DENSENET121 SOME IMPLEMENTATION WITH AI3 LIBRARY
================================================================================
CUDA Device Information:
  ✓ CUDA is available
  ✓ CUDA version: 12.4
  ✓ Number of GPUs: 1
  ✓ Current GPU: Tesla P100-PCIE-12GB
  ✓ GPU Memory: 11.9 GB
  ✓ CUDA context initialized successfully

Configuration:
  Model: DenseNet121
  Algorithm: some
  Device: cuda
  Batch size: 1
  Iterations per input size: 10
  Input sizes to test: 1

Loading DenseNet121 model...
✓ DenseNet121 model loaded successfully

Original model loaded. Analyzing structure...
Found 120 Conv2D layers in original model

Applying AI3 some algorithm conversion...
✗ Error during AI3 conversion: algorithm, some, is unsupported for conv2d
This might be due to AI3 library not being installed or configured properly.
Falling back to standard PyTorch implementation...

============================================================
MODEL STRUCTURE ANALYSIS
============================================================
⚠ PyTorch Layer: features.conv0
  - Type: Conv2d
  - In/Out channels: 3/64
⚠ PyTorch Layer: features.denseblock1.denselayer1.conv1
  - Type: Conv2d
  - In/Out channels: 64/128
⚠ PyTorch Layer: features.denseblock1.denselayer1.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock1.denselayer2.conv1
  - Type: Conv2d
  - In/Out channels: 96/128
⚠ PyTorch Layer: features.denseblock1.denselayer2.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock1.denselayer3.conv1
  - Type: Conv2d
  - In/Out channels: 128/128
⚠ PyTorch Layer: features.denseblock1.denselayer3.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock1.denselayer4.conv1
  - Type: Conv2d
  - In/Out channels: 160/128
⚠ PyTorch Layer: features.denseblock1.denselayer4.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock1.denselayer5.conv1
  - Type: Conv2d
  - In/Out channels: 192/128
⚠ PyTorch Layer: features.denseblock1.denselayer5.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock1.denselayer6.conv1
  - Type: Conv2d
  - In/Out channels: 224/128
⚠ PyTorch Layer: features.denseblock1.denselayer6.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.transition1.conv
  - Type: Conv2d
  - In/Out channels: 256/128
⚠ PyTorch Layer: features.denseblock2.denselayer1.conv1
  - Type: Conv2d
  - In/Out channels: 128/128
⚠ PyTorch Layer: features.denseblock2.denselayer1.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer2.conv1
  - Type: Conv2d
  - In/Out channels: 160/128
⚠ PyTorch Layer: features.denseblock2.denselayer2.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer3.conv1
  - Type: Conv2d
  - In/Out channels: 192/128
⚠ PyTorch Layer: features.denseblock2.denselayer3.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer4.conv1
  - Type: Conv2d
  - In/Out channels: 224/128
⚠ PyTorch Layer: features.denseblock2.denselayer4.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer5.conv1
  - Type: Conv2d
  - In/Out channels: 256/128
⚠ PyTorch Layer: features.denseblock2.denselayer5.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer6.conv1
  - Type: Conv2d
  - In/Out channels: 288/128
⚠ PyTorch Layer: features.denseblock2.denselayer6.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer7.conv1
  - Type: Conv2d
  - In/Out channels: 320/128
⚠ PyTorch Layer: features.denseblock2.denselayer7.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer8.conv1
  - Type: Conv2d
  - In/Out channels: 352/128
⚠ PyTorch Layer: features.denseblock2.denselayer8.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer9.conv1
  - Type: Conv2d
  - In/Out channels: 384/128
⚠ PyTorch Layer: features.denseblock2.denselayer9.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer10.conv1
  - Type: Conv2d
  - In/Out channels: 416/128
⚠ PyTorch Layer: features.denseblock2.denselayer10.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer11.conv1
  - Type: Conv2d
  - In/Out channels: 448/128
⚠ PyTorch Layer: features.denseblock2.denselayer11.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock2.denselayer12.conv1
  - Type: Conv2d
  - In/Out channels: 480/128
⚠ PyTorch Layer: features.denseblock2.denselayer12.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.transition2.conv
  - Type: Conv2d
  - In/Out channels: 512/256
⚠ PyTorch Layer: features.denseblock3.denselayer1.conv1
  - Type: Conv2d
  - In/Out channels: 256/128
⚠ PyTorch Layer: features.denseblock3.denselayer1.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer2.conv1
  - Type: Conv2d
  - In/Out channels: 288/128
⚠ PyTorch Layer: features.denseblock3.denselayer2.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer3.conv1
  - Type: Conv2d
  - In/Out channels: 320/128
⚠ PyTorch Layer: features.denseblock3.denselayer3.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer4.conv1
  - Type: Conv2d
  - In/Out channels: 352/128
⚠ PyTorch Layer: features.denseblock3.denselayer4.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer5.conv1
  - Type: Conv2d
  - In/Out channels: 384/128
⚠ PyTorch Layer: features.denseblock3.denselayer5.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer6.conv1
  - Type: Conv2d
  - In/Out channels: 416/128
⚠ PyTorch Layer: features.denseblock3.denselayer6.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer7.conv1
  - Type: Conv2d
  - In/Out channels: 448/128
⚠ PyTorch Layer: features.denseblock3.denselayer7.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer8.conv1
  - Type: Conv2d
  - In/Out channels: 480/128
⚠ PyTorch Layer: features.denseblock3.denselayer8.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer9.conv1
  - Type: Conv2d
  - In/Out channels: 512/128
⚠ PyTorch Layer: features.denseblock3.denselayer9.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer10.conv1
  - Type: Conv2d
  - In/Out channels: 544/128
⚠ PyTorch Layer: features.denseblock3.denselayer10.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer11.conv1
  - Type: Conv2d
  - In/Out channels: 576/128
⚠ PyTorch Layer: features.denseblock3.denselayer11.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer12.conv1
  - Type: Conv2d
  - In/Out channels: 608/128
⚠ PyTorch Layer: features.denseblock3.denselayer12.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer13.conv1
  - Type: Conv2d
  - In/Out channels: 640/128
⚠ PyTorch Layer: features.denseblock3.denselayer13.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer14.conv1
  - Type: Conv2d
  - In/Out channels: 672/128
⚠ PyTorch Layer: features.denseblock3.denselayer14.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer15.conv1
  - Type: Conv2d
  - In/Out channels: 704/128
⚠ PyTorch Layer: features.denseblock3.denselayer15.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer16.conv1
  - Type: Conv2d
  - In/Out channels: 736/128
⚠ PyTorch Layer: features.denseblock3.denselayer16.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer17.conv1
  - Type: Conv2d
  - In/Out channels: 768/128
⚠ PyTorch Layer: features.denseblock3.denselayer17.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer18.conv1
  - Type: Conv2d
  - In/Out channels: 800/128
⚠ PyTorch Layer: features.denseblock3.denselayer18.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer19.conv1
  - Type: Conv2d
  - In/Out channels: 832/128
⚠ PyTorch Layer: features.denseblock3.denselayer19.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer20.conv1
  - Type: Conv2d
  - In/Out channels: 864/128
⚠ PyTorch Layer: features.denseblock3.denselayer20.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer21.conv1
  - Type: Conv2d
  - In/Out channels: 896/128
⚠ PyTorch Layer: features.denseblock3.denselayer21.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer22.conv1
  - Type: Conv2d
  - In/Out channels: 928/128
⚠ PyTorch Layer: features.denseblock3.denselayer22.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer23.conv1
  - Type: Conv2d
  - In/Out channels: 960/128
⚠ PyTorch Layer: features.denseblock3.denselayer23.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock3.denselayer24.conv1
  - Type: Conv2d
  - In/Out channels: 992/128
⚠ PyTorch Layer: features.denseblock3.denselayer24.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.transition3.conv
  - Type: Conv2d
  - In/Out channels: 1024/512
⚠ PyTorch Layer: features.denseblock4.denselayer1.conv1
  - Type: Conv2d
  - In/Out channels: 512/128
⚠ PyTorch Layer: features.denseblock4.denselayer1.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer2.conv1
  - Type: Conv2d
  - In/Out channels: 544/128
⚠ PyTorch Layer: features.denseblock4.denselayer2.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer3.conv1
  - Type: Conv2d
  - In/Out channels: 576/128
⚠ PyTorch Layer: features.denseblock4.denselayer3.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer4.conv1
  - Type: Conv2d
  - In/Out channels: 608/128
⚠ PyTorch Layer: features.denseblock4.denselayer4.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer5.conv1
  - Type: Conv2d
  - In/Out channels: 640/128
⚠ PyTorch Layer: features.denseblock4.denselayer5.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer6.conv1
  - Type: Conv2d
  - In/Out channels: 672/128
⚠ PyTorch Layer: features.denseblock4.denselayer6.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer7.conv1
  - Type: Conv2d
  - In/Out channels: 704/128
⚠ PyTorch Layer: features.denseblock4.denselayer7.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer8.conv1
  - Type: Conv2d
  - In/Out channels: 736/128
⚠ PyTorch Layer: features.denseblock4.denselayer8.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer9.conv1
  - Type: Conv2d
  - In/Out channels: 768/128
⚠ PyTorch Layer: features.denseblock4.denselayer9.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer10.conv1
  - Type: Conv2d
  - In/Out channels: 800/128
⚠ PyTorch Layer: features.denseblock4.denselayer10.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer11.conv1
  - Type: Conv2d
  - In/Out channels: 832/128
⚠ PyTorch Layer: features.denseblock4.denselayer11.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer12.conv1
  - Type: Conv2d
  - In/Out channels: 864/128
⚠ PyTorch Layer: features.denseblock4.denselayer12.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer13.conv1
  - Type: Conv2d
  - In/Out channels: 896/128
⚠ PyTorch Layer: features.denseblock4.denselayer13.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer14.conv1
  - Type: Conv2d
  - In/Out channels: 928/128
⚠ PyTorch Layer: features.denseblock4.denselayer14.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer15.conv1
  - Type: Conv2d
  - In/Out channels: 960/128
⚠ PyTorch Layer: features.denseblock4.denselayer15.conv2
  - Type: Conv2d
  - In/Out channels: 128/32
⚠ PyTorch Layer: features.denseblock4.denselayer16.conv1
  - Type: Conv2d
  - In/Out channels: 992/128
⚠ PyTorch Layer: features.denseblock4.denselayer16.conv2
  - Type: Conv2d
  - In/Out channels: 128/32

============================================================
CONVERSION SUMMARY:
  Total Conv2D layers: 120
  AI3 converted: 0
  PyTorch remaining: 120
  Conversion rate: 0.0%
============================================================


Analyzing device placement after AI3 conversion...
✓ AI3 device distribution:
  - Parameters on CUDA: 0/364
  - Parameters on CPU: 364/364
  - Mixed device usage is expected with AI3

Starting performance testing...
This will test the model with various input sizes to measure SOME algorithm performance.

[1/1] Testing with input size 251x251
  ✓ Created input tensor: torch.Size([1, 3, 251, 251]) on cpu
  GPU Memory - Allocated: 0.00 GB, Reserved: 0.00 GB
  Running warmup...
  ✓ Warmup completed
  GPU Memory after warmup - Allocated: 0.00 GB, Reserved: 0.00 GB
  Measuring performance over 10 iterations...
    Iteration 1/10
    Iteration 6/10
  ✓ Average execution time: 68.95 ms
  Top 5 slowest layers:
    features.transition1.conv: 1.81 ms (2.6%) [pytorch_conv2d]
    features.conv0: 1.79 ms (2.6%) [pytorch_conv2d]
    features.denseblock1.denselayer6.conv1: 1.43 ms (2.1%) [pytorch_conv2d]
    features.denseblock1.denselayer5.conv1: 1.15 ms (1.7%) [pytorch_conv2d]
    features.denseblock1.denselayer1.conv2: 1.11 ms (1.6%) [pytorch_conv2d]

================================================================================
DENSENET121 SOME TESTING COMPLETED
================================================================================
Results saved to:
  - Overall performance: /home/wxs428/densenet/some/DenseNet121_some_cuda_overall.csv
  - Layer-wise performance: /home/wxs428/densenet/some/DenseNet121_some_cuda_layers.csv

Summary:
  ✓ Tested 1 different input sizes
  ✓ 10 iterations per input size
  ✓ SOME algorithm optimization using AI3 library
  ✓ Comprehensive layer-wise performance analysis

Next steps:
  1. Analyze the CSV files to compare SOME performance vs standard convolution
  2. Run the same test with different algorithms (gemm, direct, smm, etc.) for comparison
  3. Test on GPU (set device='cuda') for hardware-accelerated SOME operations
================================================================================
(ai3_env) [wxs428@gput034 some]$ vim job.sh
(ai3_env) [wxs428@gput034 some]$ vim python.py 
(ai3_env) [wxs428@gput034 some]$ 